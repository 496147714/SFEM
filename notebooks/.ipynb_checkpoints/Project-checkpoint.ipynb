{
 "metadata": {
  "name": "",
  "signature": "sha256:2db4b11248796f2c6280feae6234784dcb29dbd19538b76efaaac4c82d2e034f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "source": [
      "Assignment 4"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "Consider the linear elastic bar of length $L=$ 2m, shown in the figure below."
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "<img src=\"SFEM_bar.png\"  width=\"480\" height=\"180\" border=\"10\">"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "The axial resistance of the bar $D(z,\\theta)$ is described by a homogeneous\n",
      "random field with lognormal marginal distribution, mean $\\mu_D=$ 100kN and the\n",
      "coefficient of variation $\\delta_D = $ 0.2. The auto-correlation coefficient\n",
      "function of the underlying Gaussian random field is given by the following\n",
      "exponential model:\n",
      "\n",
      "$$\\rho_{UU}(\\Delta z) = \\exp(-\\dfrac{\\Delta z}{l})$$\n",
      "\n",
      "where $l=$ 1m is the correlation length. The random field is to be discretized\n",
      "by the Karhunen-Lo&egrave;ve expansion. The bas is subjected to a deterministic\n",
      "distributed load $q=$ 1kN/m.\n",
      "\n",
      "Based on the code written for the 2nd Assignment, create a Matlab program that\n",
      "estimates the statistics of the tip displacement by application of the\n",
      "polynomial chaos expansion.\n",
      "\n",
      "(a) Estimate the coefficients of the expansion of order 1-3 by Monte Carlo\n",
      "simulation using 10$^3$ samples. Apply either the Latin hypercube sampling or\n",
      "the quasi-random sampling.\n",
      "\n",
      "(b) Estimate the standard deviation of the tip displacement for each polynomial degree.\n",
      "\n",
      "(c) Estimate the probability density function of the tip displacement using the\n",
      "PCE approximation and the kernel density estimation. Apply the Matlab function\n",
      "`ksdensity`.\n",
      "\n",
      "The 1D normalized Hermite polynomials are given in the Matlab function\n",
      "`hermPol.m`. The sequences of the multidimensional polynomials can be computed\n",
      "using the given Matlab function `seqPCE.m`."
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "***\n",
      "\n",
      "> **NOTE:** The exercise is gonna be solved using Python instead of Matlab code.\n",
      "> The Matlab code provided in the lecture have been translated to Python.\n",
      "\n",
      "***"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "Load the plotting and numerical packages `numpy` and `matplotlib` and make the\n",
      "private modules available before starting:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt, rcParams\n",
      "import scipy.stats\n",
      "import numpy as np\n",
      "from scipy.special import factorial\n",
      "from sklearn.neighbors import KernelDensity\n",
      "import string\n",
      "import sys\n",
      "sys.path.insert(0,'../python')"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# include plots inline\n",
      "%matplotlib inline\n",
      "\n",
      "# set figure default\n",
      "rcParams['figure.figsize'] = [8.,6.]\n",
      "rcParams['font.size'] = 12.\n"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "source": [
      "Define the global variables describing the problem:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Linear elastic bar of length L=2m\n",
      "L = 2.\n",
      "\n",
      "# The axial resistance is described by a random field with lognormal marginal distribution\n",
      "# mean: mu_D = 100kN\n",
      "# coefficient of variation: delta_D = std_D / mu_D = 0.2\n",
      "mu_D    = 100.\n",
      "delta_D = 0.2\n",
      "std_D   = delta_D * mu_D\n",
      "\n",
      "# The auto-correlation coefficient function of the underlying Gaussian random\n",
      "# field is given by the following exponential model, with correlation length=1m\n",
      "l = 1. # [m]\n",
      "\n",
      "# distributed load\n",
      "q    = 1.  # [kN/m]"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "source": [
      "Code to solve all three questions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from EigFcnKL import EigFcnKL\n",
      "from relVarianceErrorKL import relVarianceErrorKL\n",
      "from avgVarianceErrorKL import avgVarianceErrorKL\n",
      "from febar import febar\n",
      "from assembleK import assembleK\n",
      "from hermPol import hermPol\n",
      "from seqPCE import seqPCE\n",
      "# maximum number of terms of the KL expansion\n",
      "m_max = 200\n",
      "\n",
      "# eigenvalues and eigenfunctions of the KL expansion with exponential kernel\n",
      "Lambda, phi, w, alpha = EigFcnKL(m_max , L , l)\n",
      "\n",
      "# Make a grid to evaluate the eigenfunctions and the errors\n",
      "N_nodes    = 21\n",
      "N_elements = N_nodes - 1\n",
      "z     = np.linspace(0, L, N_nodes)\n",
      "z_mid = (z[:-1] + z[1:]) / 2.\n",
      "\n",
      "# Make a grid to evaluate the eigenfunctions and the errors\n",
      "N_nodes    = 21\n",
      "N_elements = N_nodes - 1\n",
      "z     = np.linspace(0, L, N_nodes)\n",
      "z_mid = (z[:-1] + z[1:]) / 2.\n",
      "\n",
      "# D(z,theta) is described by a homogeneous RF with lognormal marginal distribution\n",
      "# Transform the parameters of the lognormal distribution to a normal distribution\n",
      "sigma_U =  np.sqrt(np.log(delta_D**2 + 1.))\n",
      "mu_U =  np.log(mu_D) - sigma_U**2/2.\n",
      "\n",
      "# different correlation lengths\n",
      "# l_corr = [1., 0.5]\n",
      "l_corr = [1.]\n",
      "N_corr = len(l_corr)\n",
      "\n",
      "# random seeds\n",
      "seeds = [123, 12345, 1234567, 123456789]\n",
      "\n",
      "# accuracy threshold\n",
      "avgErr_max = 0.05\n",
      "\n",
      "# errors \n",
      "errVar = []\n",
      "avgErr = []\n",
      "\n",
      "# Monte Carlo parameters\n",
      "N_repetitions  = 1\n",
      "N_realizations = 1000\n",
      "\n",
      "# initialize tip displacement\n",
      "u_tip   = np.zeros(N_realizations)\n",
      "\n",
      "# Use different types sampling methods\n",
      "samplings = ['pseudo', 'halton', 'lhs']\n",
      "N_samplings = len(samplings)\n",
      "\n",
      "# We should investigate order 1-3 of the Hermite polynomials\n",
      "p_max = 3\n",
      "pol_degrees = range(1,p_max+1)\n",
      "\n",
      "# Calculate Hermite Polynomials\n",
      "hermPolNorm = hermPol(p_max+1)\n",
      "\n",
      "# statistics\n",
      "u_tip_mean = np.zeros((p_max,N_samplings,N_corr,N_repetitions))\n",
      "u_tip_std  = np.zeros((p_max,N_samplings,N_corr,N_repetitions))\n",
      "u_tip_CV   = np.zeros((p_max,N_samplings,N_corr,N_repetitions))\n",
      "\n",
      "# probability density function\n",
      "N_pdf = 101\n",
      "u_tip_min = 0.01\n",
      "u_tip_max = 0.04\n",
      "x = np.linspace(u_tip_min, u_tip_max, N_pdf)\n",
      "pdf = np.zeros((p_max,N_samplings,N_corr,N_repetitions,N_pdf))\n",
      "\n",
      "#------------------------------------------------------------\n",
      "# loop over sampling methods\n",
      "#------------------------------------------------------------\n",
      "for ls,sampling in enumerate(samplings):\n",
      "\n",
      "    print 'Sampling: %s' % sampling\n",
      "\n",
      "    #------------------------------------------------------------\n",
      "    # loop over correlation lengths\n",
      "    #------------------------------------------------------------\n",
      "    for k,l in enumerate(l_corr):\n",
      "\n",
      "        # eigenvalues and eigenfunctions of the KL expansion with exponential kernel\n",
      "        Lambda, phi, w, alpha = EigFcnKL(m_max , L, l)\n",
      "\n",
      "        # average variance error at midpoints\n",
      "        avgErr.append(avgVarianceErrorKL(m_max, L, Lambda))\n",
      "\n",
      "        # find the first m-terms that ensure an average variance error < 0.05 \n",
      "        m = 0\n",
      "        while m < m_max:\n",
      "            m = m + 1\n",
      "            if avgErr[k][m] < avgErr_max:\n",
      "                break\n",
      "        # we will work here with d instead of m\n",
      "        d = m+1\n",
      "\n",
      "        print '  l_corr: %.2f, N_terms=%3i, avgErr[m]= %.3f' % (l, d, avgErr[k][m])\n",
      "\n",
      "        # Estimate of the coefficients for every polynomial order 'p'\n",
      "        a_k_p = []\n",
      "\n",
      "        # Save realizations of tip displacement for every polynomial order 'p'\n",
      "        u_tip_p = []\n",
      "\n",
      "        #------------------------------------------------------------\n",
      "        # Loop over polynomial order\n",
      "        #------------------------------------------------------------\n",
      "        for ip,p in enumerate(pol_degrees):\n",
      "\n",
      "            nump = int(np.round(factorial(p+d)/(factorial(p)*factorial(d))))\n",
      "            Seq = seqPCE( d,p )\n",
      "\n",
      "            # initialize Psi\n",
      "            Psi = np.empty(nump)\n",
      "            GUPsiU = np.empty((nump, N_realizations))\n",
      "\n",
      "            #------------------------------------------------------------\n",
      "            # loop over repetitions\n",
      "            #------------------------------------------------------------\n",
      "            for j in range(N_repetitions):\n",
      "\n",
      "                print '    repetition:%3i,' % (j+1),\n",
      "\n",
      "                # \"random\" sequences\n",
      "                if sampling=='pseudo':\n",
      "                    UU = np.random.randn(N_realizations,d)\n",
      "                elif sampling=='halton':\n",
      "                    import ghalton\n",
      "                    # sequencer = ghalton.Halton(m)\n",
      "                    # permutation seed | 100 permutation rules available in ghalton\n",
      "                    if j==0:\n",
      "                        pseed = np.arange(100); np.random.shuffle(pseed)\n",
      "                        sequencer = ghalton.GeneralizedHalton(d, pseed[j])\n",
      "                        hlds = np.array(sequencer.get(N_realizations*N_repetitions))\n",
      "                        hlds = np.reshape(hlds, (N_repetitions,N_realizations,d))\n",
      "                    # transform to normal\n",
      "                    UU = scipy.stats.norm.ppf(hlds[j,:,:], loc=0., scale=1.)\n",
      "                elif sampling=='lhs':\n",
      "                    from pyDOE import lhs\n",
      "                    lhd = lhs(d, samples=N_realizations)\n",
      "                    # transform to normal\n",
      "                    UU = scipy.stats.norm.ppf(lhd, loc=0., scale=1.)\n",
      "\n",
      "                #------------------------------------------------------------\n",
      "                # loop over realizations\n",
      "                #------------------------------------------------------------\n",
      "                for i in range(N_realizations):\n",
      "\n",
      "                    # Gaussian RVs\n",
      "                    U = UU[i,:]\n",
      "\n",
      "                    # Initialize Gaussian RF \n",
      "                    U_RF = np.zeros(len(z_mid))\n",
      "\n",
      "                    # Calculate Gaussian RF \n",
      "                    for ii in range(m):\n",
      "                        U_RF = U_RF + np.sqrt(Lambda[ii])*phi[ii](z_mid)*U[ii]\n",
      "\n",
      "                    U_RF = U_RF * sigma_U\n",
      "                    U_RF = U_RF + mu_U\n",
      "\n",
      "                    # Transformation to distribution of axial resistance (lognormal)\n",
      "                    D_RF = np.exp(U_RF)\n",
      "\n",
      "                    # finite element solution (random realization)\n",
      "                    u_RR = febar(D_RF, q, L, N_elements)\n",
      "\n",
      "                    # tip displacement\n",
      "                    u_tip[i] =u_RR[-1]\n",
      "\n",
      "                    # Evaluate PCEs\n",
      "                    Psi = np.ones(nump)\n",
      "                    for kk in range(nump):\n",
      "                        for jj in range(d):\n",
      "                            Psi[kk]= Psi[kk] * hermPolNorm[Seq[kk,jj]](UU[i,jj])\n",
      "\n",
      "                    # G(U)*Psi(U)\n",
      "                    GUPsiU[0:nump,i] = u_tip[i] * Psi[0:nump]\n",
      "\n",
      "                # Save realization of tip displacement\n",
      "                # u_tip_MC = u_tip[0,:]\n",
      "                u_tip_MC = GUPsiU[0,:]\n",
      "                u_tip_p.append(u_tip_MC)\n",
      "\n",
      "                # PCE coefficients\n",
      "                a_k = np.mean(GUPsiU,axis=1)\n",
      "                a_k_p.append(a_k)\n",
      "\n",
      "                # Estimation of MEAN and STD\n",
      "                U_mean = a_k[0]\n",
      "                U_var  = np.sum(a_k[1:]**2)\n",
      "                U_std  = np.sqrt(U_var)\n",
      "\n",
      "                # store the statistics for any sampling method, correlation length,\n",
      "                # repetition and polynomial order\n",
      "                u_tip_mean[ip,ls,k,j] = U_mean\n",
      "                u_tip_std[ip,ls,k,j]  = U_std\n",
      "                u_tip_CV[ip,ls,k,j]   = U_std / U_mean\n",
      "\n",
      "                print 'mean(u_tip)= %.6f, std(u_tip)= %.6f, CV(u_tip)= %.6f' % (u_tip_mean[ip,ls,k,j], u_tip_std[ip,ls,k,j], u_tip_CV[ip,ls,k,j])\n",
      "\n",
      "                # (c) Estimate the probability density function of the tip displacement\n",
      "                kde = scipy.stats.gaussian_kde(u_tip_MC)\n",
      "                # delta = (u_tip_MC.max() - u_tip_MC.min())/10.\n",
      "                # x = np.linspace(u_tip_MC.min()-delta, u_tip_MC.max()+delta, N_pdf)\n",
      "                pdf[ip,ls,k,j,:] = kde(x)\n",
      "\n",
      "                plt.figure()\n",
      "                plt.hist(u_tip_MC,bins=20, normed=True)\n",
      "                plt.plot(x,pdf[ip,ls,k,j,:],'o-')\n",
      "                plt.xlim(u_tip_min,u_tip_max)\n",
      "                plt.xlabel('tip displacement')\n",
      "                plt.ylabel('PDF of tip displacement')\n",
      "                plt.title('%s, p=%s, l_corr=%s, $\\mu=$%.6f, $\\sigma=$%.6f' % (sampling,p,l,U_mean,U_std))\n",
      "                # title('%s sampling, order p=%s' % (sampling, p))\n",
      "                plt.savefig('PDF_u_tip_l%02i_p%s_%s' % (l*10,p,sampling))\n",
      "\n",
      "                plt.show()\n"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "source": [
      "Compare PDF for different polynomial order"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#------------------------------------------------------------\n",
      "# Compare PDF for different polynomial order\n",
      "#------------------------------------------------------------\n",
      "# loop over correlation lengths\n",
      "for k,l in enumerate(l_corr):\n",
      "\n",
      "    # loop over sampling methods\n",
      "    for ls,sampling in enumerate(samplings):\n",
      "\n",
      "        fig, ax = plt.subplots()\n",
      "\n",
      "        # Loop over polynomial order\n",
      "        for ip,p in enumerate(pol_degrees):\n",
      "\n",
      "            # loop over repetitions\n",
      "            for j in range(N_repetitions):\n",
      "\n",
      "                ax.plot(x,pdf[ip,ls,k,j,:],linewidth=2,label='p=%s'%p)\n",
      "\n",
      "        ax.legend()\n",
      "        ax.set_xlabel('tip displacement')\n",
      "        ax.set_ylabel('PDF of tip displacement')\n",
      "        ax.set_xlim(u_tip_min,u_tip_max)\n",
      "        ax.set_title('%s sampling, l_corr=%s' % (sampling,l))\n",
      "        fig.savefig('PDF_u_tip_l%02i_p123_%s' % (l*10,sampling))\n"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "source": [
      "Compare PDF for different sampling methods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#------------------------------------------------------------\n",
      "# Compare PDF for different sampling methods\n",
      "#------------------------------------------------------------\n",
      "\n",
      "# loop over correlation lengths\n",
      "for k,l in enumerate(l_corr):\n",
      "\n",
      "    # Loop over polynomial order\n",
      "    for ip,p in enumerate(pol_degrees):\n",
      "\n",
      "        fig, ax = plt.subplots()\n",
      "\n",
      "        # loop over sampling methods\n",
      "        for ls,sampling in enumerate(samplings):\n",
      "\n",
      "            # loop over repetitions\n",
      "            for j in range(N_repetitions):\n",
      "\n",
      "                ax.plot(x,pdf[ip,ls,k,j,:],linewidth=2,label='%s'%sampling)\n",
      "                \n",
      "        ax.legend()\n",
      "        ax.set_xlabel('tip displacement')\n",
      "        ax.set_ylabel('PDF of tip displacement')\n",
      "        ax.set_xlim(u_tip_min,u_tip_max)\n",
      "        ax.set_title('p=%s, l_corr=%s' % (p,l))\n",
      "        fig.savefig('PDF_u_tip_l%02i_p%s_samplings' % (l*10,p))\n",
      "\n"
     ],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}